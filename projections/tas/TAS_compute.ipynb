{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import glob\n",
    "import os\n",
    "import scipy.stats\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import dask\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "if __name__ == \"__main__\":\n",
    "    cluster=LocalCluster(host=\"tcp://127.0.0.1:2459\",dashboard_address=\"127.0.0.1:2461\",n_workers=4)\n",
    "    client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [x.split('/')[-1] for x in glob.glob(\"/terra/data/cmip5/global/rcp85/*\")]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda3/envs/dask/lib/python3.8/site-packages/xarray/core/indexing.py:1369: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for model in models:\n",
    "    try:\n",
    "        rcp85_files = sorted(glob.glob(\"/terra/data/cmip5/global/rcp85/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))\n",
    "        rcp85 = xr.open_mfdataset(rcp85_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "        rcp85 = rcp85.sel(time = slice('2000','2250'))\n",
    "        hist_files = sorted(glob.glob(\"/terra/data/cmip5/global/historical/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))\n",
    "        hist = xr.open_mfdataset(hist_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "        x = xr.concat([hist,rcp85],dim='time').load()\n",
    "        x = x.sortby(x.time)\n",
    "        x = x.resample(time='M').mean()\n",
    "        dic[model] = x - hist.sel(time=slice('1979','2005')).mean(dim='time')\n",
    "    except:\n",
    "        if model == 'BNU-ESM': # no historical monthly data \n",
    "            rcp85_files = sorted(glob.glob(\"/terra/data/cmip5/global/rcp85/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))\n",
    "            rcp85 = xr.open_mfdataset(rcp85_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            rcp85 = rcp85.sel(time = slice('2000','2250'))\n",
    "            hist_files = sorted(glob.glob(\"/terra/data/cmip5/global/historical/\"+str(model)+\"/r1i1p1/day/native/tas_*\"))\n",
    "            hist = xr.open_mfdataset(hist_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            hist = hist.resample(time='M').mean()\n",
    "            x = xr.concat([hist,rcp85],dim='time').load()\n",
    "            x = x.sortby(x.time)\n",
    "            x = x.resample(time='M').mean()\n",
    "            dic[model] = x - hist.sel(time=slice('1979','2005')).mean(dim='time')\n",
    "        elif model == 'MPI-ESM-LR': # a problem with the later than 2100 data\n",
    "            rcp85_files = sorted(glob.glob(\"/terra/data/cmip5/global/rcp85/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))[0]\n",
    "            rcp85 = xr.open_mfdataset(rcp85_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            rcp85 = rcp85.sel(time = slice('2000','2250'))\n",
    "            hist_files = sorted(glob.glob(\"/terra/data/cmip5/global/historical/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))\n",
    "            hist = xr.open_mfdataset(hist_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            x = xr.concat([hist,rcp85],dim='time').load()\n",
    "            x = x.sortby(x.time)\n",
    "            x = x.resample(time='M').mean()\n",
    "            dic[model] = x - (x.sel(time=slice('1979','2005')).mean(dim='time'))\n",
    "        elif model == 'CNRM-CM5': # a problem with the later than 2100 data\n",
    "            rcp85_files = sorted(glob.glob(\"/terra/data/cmip5/global/rcp85/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))[:2]\n",
    "            rcp85 = xr.open_mfdataset(rcp85_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            rcp85 = rcp85.sel(time = slice('2000','2250'))\n",
    "            hist_files = sorted(glob.glob(\"/terra/data/cmip5/global/historical/\"+str(model)+\"/r1i1p1/mon/native/tas_*\"))\n",
    "            hist = xr.open_mfdataset(hist_files, decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').tas\n",
    "            x = xr.concat([hist,rcp85],dim='time').load()\n",
    "            x = x.sortby(x.time)\n",
    "            x = x.resample(time='M').mean()\n",
    "            dic[model] = x - (x.sel(time=slice('1979','2005')).mean(dim='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOAA\n",
    "x = xr.open_mfdataset('/home/pmarsh/NOAA_2deg/air.2m.mon.mean.nc', decode_cf=True).sel(lat = -34, method = 'nearest').sel(lon = 18, method = 'nearest').air\n",
    "x = x.sortby(x.time)\n",
    "x = x.resample(time='M').mean()\n",
    "x = x.sel(time=slice('1940','2016'))\n",
    "dic['NOAA'] = x - (x.sel(time=slice('1979','2005')).mean(dim='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERA5 - 1hr - daily avalable but missing some data \n",
    "x = xr.open_mfdataset(sorted(glob.glob('/terra/data/reanalysis/global/reanalysis/ECMWF/ERA5/1hr/native/tas_*')), decode_cf=True).sel(latitude = -34, method = 'nearest').sel(longitude = 18, method = 'nearest').tas\n",
    "x = x.resample(time='M').mean()\n",
    "x = x.sortby(x.time).load()\n",
    "dic['ERA5'] = x - (x.sel(time=slice('1979','2005')).mean(dim='time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dic, open( \"monthly_tas_dic.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dask [shared installation]",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
