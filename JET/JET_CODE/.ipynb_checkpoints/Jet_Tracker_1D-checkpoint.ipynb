{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pressure_weighted(x):\n",
    "    dPref = (x.plev.values[0]-x.plev.values[-1])  #(p-ps)\n",
    "    integral = []\n",
    "    for i in range(len(x.plev)): #Integral of variable from P to Ps calculated as area between each pressure variable trapezoid then summed\n",
    "        if i+1 < len(x.plev):\n",
    "            area=((x.loc[dict(plev=x.plev.values[i])] + x.loc[dict(plev=x.plev.values[i+1])])/2)*(x.plev.values[i]-x.plev.values[i+1])\n",
    "            integral.append(area)\n",
    "    pw = (sum(integral))/dPref\n",
    "    return(pw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasoning(month):\n",
    "    if (month == 12) | (month == 1) | (month == 2):\n",
    "        return(1)\n",
    "    if (month == 3) | (month == 4) | (month == 5):\n",
    "        return(2)\n",
    "    if (month == 6) | (month == 7) | (month == 8):\n",
    "        return(3)\n",
    "    if (month == 9) | (month == 10) | (month == 11):\n",
    "        return(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_weights(window, cutoff):\n",
    "    order = ((window - 1) // 2 ) + 1\n",
    "    nwts = 2 * order + 1\n",
    "    w = np.zeros([nwts])\n",
    "    n = nwts // 2\n",
    "    w[n] = 2 * cutoff\n",
    "    k = np.arange(1., n)\n",
    "    sigma = np.sin(np.pi * k / n) * n / (np.pi * k)\n",
    "    firstfactor = np.sin(2. * np.pi * cutoff * k) / (np.pi * k)\n",
    "    w[n-1:0:-1] = firstfactor * sigma\n",
    "    w[n+1:-1] = firstfactor * sigma\n",
    "    return w[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrange(numbers):\n",
    "    return max(numbers) - min(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jettracker(model,file,levels=[85000,70000],time=['1950', '2005'],infer = np.linspace(-75, 15, 501)):\n",
    "    d = xr.open_mfdataset(file)\n",
    "    print(model)\n",
    "    if model == 'NOAA':\n",
    "        d = d.rename({'uwnd':'ua'})\n",
    "        d = d.rename({'level':'plev'})\n",
    "        levels=[850,700]\n",
    "    elif model == 'ERA5':\n",
    "        d = d.rename({'latitude':'lat'})\n",
    "        d = d.rename({'longitude':'lon'})\n",
    "        d = d.rename({'level':'plev'})\n",
    "        levels=[850,700]\n",
    "        time=['1980','2018']\n",
    "    d = xr.concat([d.sel(lon = slice(0,30)),d.sel(lon = slice(320,360))],dim='lon')\n",
    "    d.coords['lon'] = (d.coords['lon'] + 180) % 360 - 180\n",
    "    if model == 'ERA5':\n",
    "        d = d.sel(lat = slice(-15,-75))\n",
    "        d = d.sel(time = slice('1980','2018'))\n",
    "    else:\n",
    "        d = d.sel(lat = slice(-75,-15))\n",
    "    wgts = low_pass_weights(41, 1/10)\n",
    "    weight = xr.DataArray(list(wgts), dims=['window'])\n",
    "    _, index = np.unique(d['time'], return_index=True)\n",
    "    d = d.isel(time=index)\n",
    "    d = d.sel(plev=levels,method='nearest')\n",
    "    d = d.sel(time=slice(time[0], time[-1]))\n",
    "    d = get_pressure_weighted(d.ua)\n",
    "    d = d.rolling(time=41, center=True).construct('window').dot(weight)\n",
    "    d = d[20:-21]\n",
    "    d = d.mean(dim='lon',skipna=True)\n",
    "    d = d.sortby(d.lat)\n",
    "    #d = d.load() #this is faster than loading later but ERA5 reaches a RAM limit - Memory leak from open_mfdataset also a recurring problem\n",
    "    out = []\n",
    "    size = len(d.lat)-1\n",
    "    for y in pd.date_range(str(int(time[0])+1),time[-1], freq='A'): #1980-2004\n",
    "        a = d.sel(time = str(y.year))\n",
    "        a = a.load()\n",
    "        b = a.where(a==a.max(dim='lat')) #find max zonal mean/set rest to Nan\n",
    "        for i in range(len(a.values)): #each day\n",
    "            fwhm=[]\n",
    "            for j in range(len(a.values[i])): #each lat\n",
    "                if math.isnan(b.values[i][j])==False: #if a maximum is found\n",
    "                    if j==0 or j==size:\n",
    "                        lat = a.lat.values[j]\n",
    "                        ua = b.values[i][j]\n",
    "                        break\n",
    "                    else:\n",
    "                        p = np.poly1d(np.polyfit(b.lat.values[j-1:j+2],a.values[i][j-1:j+2],2)) #fit quadratic to interpolate\n",
    "                        lat = pd.DataFrame(p(infer),index=infer).idxmax().values[0]\n",
    "                        ua = pd.DataFrame(p(infer),index=infer).max().values[0]\n",
    "                        break\n",
    "            for k in range(len(b.lat.values)): #check against each lat to find width\n",
    "                if a.values[i][k] >= ua/2:\n",
    "                    fwhm.append(k) #full width half mean\n",
    "            if len(fwhm) >= 2: #some days no latitudes other than maximum meet fwhm criteria\n",
    "                if fwhm[0]==0: #if bottom is maximum latitude else interpolate with linear model\n",
    "                    bottom = b.lat.values[fwhm[0]]\n",
    "                else:\n",
    "                    wb = np.poly1d(np.polyfit(b.lat.values[fwhm[0]-1:fwhm[0]+2],a.values[i][fwhm[0]-1:fwhm[0]+2],1))\n",
    "                    inf = infer\n",
    "                    bottom = inf[find_nearest(wb(inf),ua/2)]\n",
    "                if fwhm[-1]==size: #if top is minimum latitude else interpolate with linear model\n",
    "                    top = b.lat.values[fwhm[-1]]\n",
    "                else:\n",
    "                    wt = np.poly1d(np.polyfit(b.lat.values[fwhm[-1]-1:fwhm[-1]+2],a.values[i][fwhm[-1]-1:fwhm[-1]+2],1))\n",
    "                    inf = infer\n",
    "                    top = inf[find_nearest(wt(inf),ua/2)]\n",
    "                width = top - bottom\n",
    "            else:\n",
    "                width = np.nan\n",
    "            out.append([a[i].time.values,lat,ua,width,top,bottom]) #append to list\n",
    "            a.close()\n",
    "    df = pd.DataFrame(np.array(out),columns=['time', 'lat', 'ua','width','top','bottom'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files():\n",
    "    models = glob.glob(\"/terra/data/cmip5/global/historical/*\")\n",
    "    avail={}\n",
    "    for model in models:\n",
    "        ua = glob.glob(str(model)+\"/r1i1p1/day/native/ua_*\")\n",
    "        try:\n",
    "            test = ua[0]\n",
    "            avail[model.split('/')[-1]] = ua\n",
    "        except:\n",
    "             pass\n",
    "    return avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files['NOAA'] =  glob.glob(\"/terra/data/reanalysis/global/reanalysis/NOAA/20thC/r1/day/native/ua_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files['ERA5'] = glob.glob(\"/terra/data/reanalysis/global/reanalysis/ECMWF/ERA5/day/native/ua_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERA5\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for model in dic:\n",
    "    dic[model] = jettracker(model,files[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_files = {}\n",
    "for index in dic:\n",
    "    if index == 'NOAA':\n",
    "        pr_files[index] = glob.glob(\"/terra/data/reanalysis/global/reanalysis/NOAA/20thC/r1/day/native/pr*\")\n",
    "    elif index == 'ERA5':\n",
    "        pr_files[index] = glob.glob(\"/terra/data/reanalysis/global/reanalysis/ECMWF/ERA5/day/native/pr*\")\n",
    "    else:\n",
    "        pr_files[index] = glob.glob(\"/terra/data/cmip5/global/historical/\"+str(index)+\"/r1i1p1/day/native/pr*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM5A-LR\n",
      "MPI-ESM-MR\n",
      "MRI-ESM1\n",
      "MIROC-ESM-CHEM\n",
      "EC-EARTH\n",
      "HadGEM2-CC\n",
      "bcc-csm1-1-m\n",
      "FGOALS-g2\n",
      "ACCESS1-0\n",
      "MIROC-ESM\n",
      "CSIRO-Mk3-6-0\n",
      "GFDL-CM3\n",
      "CanESM2\n",
      "IPSL-CM5B-LR\n",
      "MPI-ESM-LR\n",
      "CMCC-CM\n",
      "GFDL-ESM2G\n",
      "MIROC5\n",
      "MPI-ESM-P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda3/envs/dask/lib/python3.8/site-packages/xarray/coding/times.py:113: SerializationWarning: Ambiguous reference date string: 850-1-1 00:00:00. The first value is assumed to be the year hence will be padded with zeros to remove the ambiguity (the padded reference date string is: 0850-1-1 00:00:00). To remove this message, remove the ambiguity by padding your reference date strings with zeros.\n",
      "  warnings.warn(warning_msg, SerializationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMCC-CMS\n",
      "CNRM-CM5\n",
      "IPSL-CM5A-MR\n",
      "inmcm4\n",
      "ACCESS1-3\n",
      "MRI-CGCM3\n",
      "bcc-csm1-1\n",
      "CMCC-CESM\n",
      "HadGEM2-AO\n",
      "BNU-ESM\n",
      "NorESM1-M\n",
      "HadCM3\n",
      "GFDL-ESM2M\n",
      "MIROC4h\n",
      "NOAA\n",
      "ERA5\n"
     ]
    }
   ],
   "source": [
    "for model in dic:\n",
    "    print(model)\n",
    "    x = xr.open_mfdataset(pr_files[model])\n",
    "    _, index = np.unique(x['time'], return_index=True)\n",
    "    x = x.isel(time=index)\n",
    "    if model == 'ERA5':\n",
    "        x = x.sel(time = slice('1981','2017'))\n",
    "        x = x.sel(latitude=-34,method='nearest')\n",
    "        x = x.sel(longitude=18,method='nearest')        \n",
    "    else:\n",
    "        x = x.sel(time=slice('1951', '2004'))\n",
    "        x = x.sel(lat=-34,method='nearest')\n",
    "        x = x.sel(lon=18,method='nearest')\n",
    "    if model == 'NOAA':\n",
    "        x = x.prate.values\n",
    "    else:\n",
    "        x = x.pr.values\n",
    "    dic[model]['pr'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM5A-LR\n",
      "MPI-ESM-MR\n",
      "MRI-ESM1\n",
      "MIROC-ESM-CHEM\n",
      "EC-EARTH\n",
      "HadGEM2-CC\n",
      "bcc-csm1-1-m\n",
      "FGOALS-g2\n",
      "ACCESS1-0\n",
      "MIROC-ESM\n",
      "CSIRO-Mk3-6-0\n",
      "GFDL-CM3\n",
      "CanESM2\n",
      "IPSL-CM5B-LR\n",
      "MPI-ESM-LR\n",
      "CMCC-CM\n",
      "GFDL-ESM2G\n",
      "MIROC5\n",
      "MPI-ESM-P\n",
      "CMCC-CMS\n",
      "CNRM-CM5\n",
      "IPSL-CM5A-MR\n",
      "inmcm4\n",
      "ACCESS1-3\n",
      "MRI-CGCM3\n",
      "bcc-csm1-1\n",
      "CMCC-CESM\n",
      "HadGEM2-AO\n",
      "BNU-ESM\n",
      "NorESM1-M\n",
      "HadCM3\n",
      "GFDL-ESM2M\n",
      "MIROC4h\n",
      "NOAA\n",
      "ERA5\n"
     ]
    }
   ],
   "source": [
    "arraytype = type(dic['bcc-csm1-1-m'].time[0])\n",
    "for index in dic:\n",
    "    years=[]\n",
    "    months=[]\n",
    "    print(index)\n",
    "    for i in range(len(dic[index])):\n",
    "        if isinstance(dic[index].time[i], arraytype):\n",
    "            years.append(dic[index].time[i].ravel()[0].year)\n",
    "            months.append(dic[index].time[i].ravel()[0].month)\n",
    "        else:\n",
    "            years.append(dic[index].time[i].year)\n",
    "            months.append(dic[index].time[i].month)\n",
    "    dic[index]['years'] = years\n",
    "    dic[index]['months'] = months\n",
    "for index in dic:\n",
    "    dic[index]['seasons'] = [seasoning(i) for i in dic[index].months.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dic, open( \"../JET_OUT/jettrack_1D.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dask [shared installation]",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
