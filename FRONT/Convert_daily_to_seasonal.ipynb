{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models initially saved as 3-hourly - now converted to seasonal to reduce storage need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import math\n",
    "import dask\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from dask.distributed import Client, LocalCluster\n",
    "if __name__ == \"__main__\":\n",
    "    cluster=LocalCluster(host=\"tcp://127.0.0.1:2419\",dashboard_address=\"127.0.0.1:2429\",n_workers=4)\n",
    "    client = Client(cluster)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../FRONT_FILES/2deg/3-hourly/*_front.*\")\n",
    "files.append(\"../FRONT_FILES/2deg/3-hourly/ERA5_front_6hr.nc\")\n",
    "files.append(\"../FRONT_FILES/2deg/3-hourly/NOAA_front_6hr.nc\")\n",
    "\n",
    "models = []\n",
    "for file in files:\n",
    "    models.append(file.split('/')[-1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-ESM2M\n",
      "MIROC-ESM-CHEM\n",
      "ACCESS1-3\n",
      "BNU-ESM\n",
      "MIROC4h\n",
      "IPSL-CM5A-LR\n",
      "MRI-CGCM3\n",
      "IPSL-CM5A-MR\n",
      "CNRM-CM5\n",
      "MIROC-ESM\n",
      "bcc-csm1-1-m\n",
      "GFDL-CM3\n",
      "ACCESS1-0\n",
      "MRI-ESM1\n",
      "bcc-csm1-1\n",
      "MIROC5\n",
      "GFDL-ESM2G\n",
      "ERA5\n",
      "NOAA\n"
     ]
    }
   ],
   "source": [
    "for model,file in zip(models,files):\n",
    "    print(model)\n",
    "    x = xr.open_mfdataset(file)\n",
    "    x = x.rename({'longitude':'lon'})\n",
    "    x = x.rename({'latitude':'lat'})\n",
    "    zero = x.where(x.time.dt.hour == 0).dropna(dim='time',how='all')\n",
    "    twelve = x.where(x.time.dt.hour == 12).dropna(dim='time',how='all')\n",
    "    x = xr.DataArray(np.concatenate([zero.front.values,twelve.front.values]),dims=(\"time\",\"lat\", \"lon\"), coords={\"time\":np.concatenate([zero.time.values,twelve.time.values]),\"lon\":zero.lon.values ,\"lat\": zero.lat.values})\n",
    "    x = x.sortby(x.time)\n",
    "    x = x.resample(time = 'QS-DEC').sum()\n",
    "    x.to_netcdf(path='../FRONT_FILES/2deg/3-hourly/'+str(model)+'_seasonal_fronts_2deg.nc', mode='w')\n",
    "    x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../FRONT_FILES/native/3-hourly/*.nc\")\n",
    "\n",
    "models = []\n",
    "for file in files:\n",
    "    models.append(file.split('/')[-1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL-CM3\n"
     ]
    }
   ],
   "source": [
    "for file,model in zip(files,models):\n",
    "    x = xr.open_mfdataset(file)\n",
    "    x = x.rename({'longitude':'lon'})\n",
    "    x = x.rename({'latitude':'lat'})\n",
    "    zero = x.where(x.time.dt.hour == 0).dropna(dim='time',how='all')\n",
    "    twelve = x.where(x.time.dt.hour == 12).dropna(dim='time',how='all')\n",
    "    x = xr.DataArray(np.concatenate([zero.front.values,twelve.front.values]),dims=(\"time\",\"lat\", \"lon\"), coords={\"time\":np.concatenate([zero.time.values,twelve.time.values]),\"lon\":zero.lon.values ,\"lat\": zero.lat.values})\n",
    "    x = x.sortby(x.time)\n",
    "    x = x.resample(time = 'QS-DEC').sum()\n",
    "    x.to_netcdf(path='../FRONT_FILES/native/3-hourly/'+str(model)+'_seasonal_fronts_native.nc', mode='w')\n",
    "    x.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if this worked quickly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"../FRONT_FILES/2deg/3-hourly/*_2deg.nc\")\n",
    "\n",
    "models = []\n",
    "for file in files:\n",
    "    models.append(file.split('/')[-1].split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xr.open_mfdataset(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dask [shared installation]",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
